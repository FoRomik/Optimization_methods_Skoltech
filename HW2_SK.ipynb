{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Methods, Homework â„–2 - Demidov Andrei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to given task, we have the following dimensions in expression:\n",
    "$$\n",
    "    x^T A y - 3 x^T = (1,k) (n,m) (m,1) - 3(1,k)\n",
    "$$\n",
    "\n",
    "In case of $k = n$:\n",
    "$$\n",
    "    x^T A y - 3 x^T = (1,k) (n,m) (m,1) - 3(1,k) = (1,1) - 3(1,n)\n",
    "$$\n",
    "\n",
    "To make the operation valid, there is a need to make a constaint for variable $n$, $n=1$.\n",
    "\n",
    "$Answer:$ if $k=n=1$ the expression is valid;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an expression, $x^T M x$, $x \\in R^n$. Hense,\n",
    "$$\n",
    "    x^T M x \\Rightarrow (1,n)(a,b)(n,1), \n",
    "$$\n",
    "$ a,b $ - dimensions of matrix $A$\n",
    "\n",
    "To make the operation valid, the dimensions of matrix $A$ should be $(n,n)$.\n",
    "\n",
    "$Answer:$ (n,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Taylor series for the natural logarithm $log(x)$ with respect to the point $a > 0$ is the following:\n",
    "$$\n",
    "    log(x) = log(a) + \\frac{1}{a}(x-a) - \\frac{1}{2a^2} (x-a)^2 + \\frac{1}{3a^3} (x-a)^3 - \\frac{1}{4a^4} (x-a)^4 + o((x-a)^4)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(x) = ax^2 + bx + c$\n",
    "\n",
    "The first derivative of the function $f$ with respect to $x$ is:\n",
    "$$\n",
    "\\frac{df}{dx} = 2ax+b\n",
    "$$\n",
    "Let's equal the expression to zero and find the mininum:\n",
    "$$\n",
    "\\frac{df}{dx} = 2ax+b = 0 \\Rightarrow x = \\frac{-b}{2a}\n",
    "$$\n",
    "\n",
    "Also we need to find the second derivative to understand the conditions for the minimum:\n",
    "$$\n",
    "\\frac{d^2f}{dx^2} = 2a\n",
    "$$\n",
    "\n",
    "Hense, to get the minimum point, the variable $a$ must be positive: $a > 0$.\n",
    "\n",
    "$Answer:$\n",
    "$a > 0, b \\in R \\Rightarrow$ The minimum is $x^*=\\frac{-b}{2a}$, $f(x^*)=\\frac{-b^2}{4a}+c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the task, there is just a need to fill the gaps.\n",
    "\n",
    "$Answer: \\bigtriangledown h(x) \\in R$, shape is $(m,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial conditions: $\\frac{\\mu}{2}\\|x-x^* \\| \\leq f(x) - f^*$\n",
    "\n",
    "There is a need to represent the function $f$ in the point $x*$ using the Taylor series.\n",
    "\n",
    "$\n",
    "f(x) = f(x^*) + \\frac{f'(x^*)}{1!} (x-x^*) + \\frac{f''(x^*)}{2!} (x-x^*)^2 + o(||x-x^*||)\n",
    "$\n",
    "\n",
    "$\n",
    "f(x) - f(x^*) = \\frac{f'(x^*)}{1!} (x-x^*) + \\frac{f''(x^*)}{2!} (x-x^*)^2 + o(||x-x^*||)\n",
    "$\n",
    "\n",
    "The point $x^*$ is the minimum. Consequently, $f'(x^*)$ is equal to zero. Also, according to the following document: https://www.princeton.edu/~amirali/Public/Teaching/ORF523/S17/ORF523_S17_Lec7_gh.pdf, page 9, the function is strongly convex iff there is a positive $\\mu$ such as $f''(x) \\geq \\mu \\geq 0$.\n",
    "\n",
    "That's why the following expression is right:\n",
    "\n",
    "$$\n",
    "f(x) - f(x^*) = \\frac{f''(x^*)}{2!} (x-x^*)^2 + o(||x-x^*||) \\geq \\frac{\\mu}{2!} ||x-x^*||^2_2\n",
    "$$\n",
    "\n",
    "Hense,\n",
    "\n",
    "$$\n",
    "f(x) - f(x^*) \\geq \\frac{\\mu}{2} ||x-x^*||^2_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial conditions:\n",
    "\n",
    "$f(x)=\\frac{1}{x}$, $dom (f) = \\{x:x>0\\}$\n",
    "\n",
    "$f^*(y)=sup(xy-\\frac{1}{x})$\n",
    "\n",
    "There is a need to find the first derivative of $f^*(x)$:\n",
    "\n",
    "$\\frac{d}{dx} (xy-\\frac{1}{x})=y+\\frac{1}{x^2}=0 \\Rightarrow x = \\pm \\sqrt{\\frac{1}{-y}}$\n",
    "\n",
    "According the the provided constraints, just one case is an appropriate: $x = \\sqrt{\\frac{1}{-y}}$, $y < 0$\n",
    "\n",
    "$f^*(y)=\\sqrt{\\frac{1}{-y}}y-\\sqrt{-y}$, $dom(f^*)= \\{y < 0\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial conditions: $f^*(y), f(y), g(x)=f(x)+(c,x)+d$\n",
    "\n",
    "The conjugate function for the function $g(x)$ is:\n",
    "$$\n",
    "    g^*(y) = sup(xy - g(y)) = sup(xy - f(x) - (c,x) - d)\n",
    "$$\n",
    "\n",
    "Let's calculate the first derivative of $g^*(y)$:\n",
    "\n",
    "$\\frac{d}{dx}(xy - f(x) - (c,x) - d) = y - \\nabla f(x) - c = 0$\n",
    "\n",
    "Using the information about the solution for $f^*$, if $t = y - c$ then the solution exists.\n",
    "\n",
    "Hence, \n",
    "$$\n",
    "    g^*(y) = f^*(y-c)-d\n",
    "$$\n",
    "\n",
    "The domain of $g^*(y)$ is the same as the domain of the function $f^*(y)$ but it is shifted by the value $c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f = (x,c)^2$\n",
    "\n",
    "$\\nabla f = 2c_i(x,c)$, where $i$ is the index of gradient vector.\n",
    "\n",
    "The Hessian $H$ is $2 c_i c_j$, where $i,j$ are the indices of the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x)=g(Ax+b)$$\n",
    "\n",
    "Let's make a replacement: $c = Ax+b$ and get the gradient\n",
    "\n",
    "$$\\frac{df}{dx_i}=\\frac{df}{dg} \\frac{dg}{dc} \\frac{dc}{dx_i}=A_i \\frac{dg}{dc}$$\n",
    "\n",
    "Last step is to calculate the Hessian matrix:\n",
    "\n",
    "$$\\frac{d^2f}{dx_i dx_j}=A_i \\frac{dg}{dc} \\frac{dc}{dx_j} = A_i A_j \\frac{d^2g}{dc^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the definition of first order convexity, there is the following expression:\n",
    "$f(y) \\geq f(x) + \\nabla f^T(x)(y-x), \\forall x,y$\n",
    "\n",
    "Let's suggest $x_0$ is the point of global minimum.\n",
    "\n",
    "In this case, \n",
    "\n",
    "$f(y) \\geq f(x_0) + \\nabla f^T(x_0)(y-x_0), \\forall y$\n",
    "\n",
    "If the $\\nabla f(x_0)=0$, then\n",
    "\n",
    "$f(y) \\geq f(x_0), \\forall y$\n",
    "\n",
    "To conclude, $x_0$ is the global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given conditions: $f(\\gamma) = (A(x + \\gamma d), x + \\gamma d) + (b, x + \\gamma d) \\rightarrow min_{\\gamma}$\n",
    "\n",
    "\n",
    "Let's make the following transformations:\n",
    "\n",
    "$$\n",
    "f(\\gamma) = (A x + \\gamma A d, x + \\gamma d) + (b, x + \\gamma d)\n",
    "$$\n",
    "$$\n",
    "f(\\gamma) = x^T A x + \\gamma x^T A d + \\gamma d^T A x + \\gamma^2 d^T A d + b^T x + \\gamma b^T d\n",
    "$$\n",
    "\n",
    "There is a need to find the derivative:\n",
    "\n",
    "$$\n",
    "\\frac{df(\\gamma)}{d\\gamma} = x^T A d +  d^T A x + 2 \\gamma d^T A d + b^T d = 0\n",
    "$$\n",
    "\n",
    "Hence,\n",
    "\n",
    "$$\n",
    "    \\gamma = \\frac{-b^T d - x^T A d - d^T A d}{2 d^T A d}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13\n",
    "\n",
    "#### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given condition: $f(x)=[x^2-1]_+ = max(expression, 0)$ It means that the function is equal to zero in the line $[-1,1]$. At the points $x=1,-1$ the function is not differentiable.\n",
    "\n",
    "The definition of subgradient is the following:\n",
    "\n",
    "$$\n",
    "    df(x) = \\{g|f(y)-f(x) \\geq g^T(y-x), y \\in dom(f)\\}\n",
    "$$\n",
    "\n",
    "$Answer:$ Subgradient (subdifferential) is equal to the following cases:\n",
    "\n",
    "1. $2x$, if $x <  -1$ and $ x > 1$;\n",
    "2. $0$, if $ x > -1$ and $x < 1$;\n",
    "3. $[0;2]$, if $x = 1$;\n",
    "4. $[-2;0]$, if $x = -1$;\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
